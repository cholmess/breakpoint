{
  "id": "config-b",
  "model": "gpt-4",
  "context_window": 16384,
  "top_k": 4,
  "chunk_size": 1024,
  "max_output_tokens": 4096,
  "tools_enabled": false,
  "temperature": 0.5,
  "cost_per_1k_tokens": 0.03
}
